{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R4: 模型高效服務\n",
    "- 向量資料庫\n",
    "- 量化服務"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import re\n",
    "import chromadb\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量資料庫的基本操作\n",
    "Chroma 是用於建立具有嵌入向量（vector embedding）的 AI 應用程式的向量資料庫。它們可以表示文字、圖像，很快還可以表示音訊和視訊。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立DB\n",
    "集合（資料庫名稱）是您儲存嵌入、文件和任何其他元資料的地方。您可以建立一個具有以下名稱的集合（相當於關係資料庫mysql裡面的資料庫名稱）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Chroma Client\n",
    "chroma_client = chromadb.PersistentClient(path=\"document_store\")\n",
    "# Create a collection\n",
    "collection = chroma_client.get_or_create_collection(name=\"collection_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 匯入資料\n",
    "這裡的documents是你的數據內容，元數據（Metadata）是關於數據的組織、數據域及其關係的信息，簡言之，元數據就是關於數據的數據，可以你自己定義的章節等內容，ids是索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlyu0419\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|██████████| 79.3M/79.3M [01:11<00:00, 1.16MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': None,\n",
      " 'documents': ['This is a document about pineapple',\n",
      "               'This is a document about oranges',\n",
      "               'This is a document about mango',\n",
      "               'This is a document about apple'],\n",
      " 'embeddings': None,\n",
      " 'ids': ['id1', 'id2', 'id3', 'id4'],\n",
      " 'included': ['metadatas', 'documents'],\n",
      " 'metadatas': [{'chapter': '1', 'verse': 'a'},\n",
      "               {'chapter': '1', 'verse': 'a'},\n",
      "               {'chapter': '2', 'verse': 'a'},\n",
      "               {'chapter': '2', 'verse': 'a'}],\n",
      " 'uris': None}\n"
     ]
    }
   ],
   "source": [
    "collection.add(\n",
    "    documents=[\n",
    "        \"This is a document about pineapple\",\n",
    "        \"This is a document about oranges\",\n",
    "        \"This is a document about mango\",\n",
    "        \"This is a document about apple\",\n",
    "    ],\n",
    "    metadatas=[{\"chapter\": \"1\", \"verse\": \"a\"},\n",
    "          {\"chapter\": \"1\", \"verse\": \"a\"},\n",
    "          {\"chapter\": \"2\", \"verse\": \"a\"},\n",
    "          {\"chapter\": \"2\", \"verse\": \"a\"}],\n",
    "    ids=[\"id1\", \"id2\", \"id3\", \"id4\"]\n",
    ")\n",
    "pprint(collection.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 讀取DB\n",
    "讀取先前保存好的db，當document龐大時不用每次都重新轉embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': None,\n",
      " 'documents': ['This is a document about pineapple',\n",
      "               'This is a document about oranges',\n",
      "               'This is a document about mango',\n",
      "               'This is a document about apple'],\n",
      " 'embeddings': None,\n",
      " 'ids': ['id1', 'id2', 'id3', 'id4'],\n",
      " 'included': ['metadatas', 'documents'],\n",
      " 'metadatas': [{'chapter': '1', 'verse': 'a'},\n",
      "               {'chapter': '1', 'verse': 'a'},\n",
      "               {'chapter': '2', 'verse': 'a'},\n",
      "               {'chapter': '2', 'verse': 'a'}],\n",
      " 'uris': None}\n"
     ]
    }
   ],
   "source": [
    "client2 = chromadb.PersistentClient(path=\"document_store\")\n",
    "collection2 = client2.get_or_create_collection(name=\"collection_name\")\n",
    "pprint(collection2.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 檢索資料\n",
    "根據問題檢索文檔的相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': None,\n",
      " 'distances': [[1.0404008937271816,\n",
      "                1.1399504747618734,\n",
      "                1.2430800215233073,\n",
      "                1.3259602282234746]],\n",
      " 'documents': [['This is a document about pineapple',\n",
      "                'This is a document about mango',\n",
      "                'This is a document about oranges',\n",
      "                'This is a document about apple']],\n",
      " 'embeddings': None,\n",
      " 'ids': [['id1', 'id3', 'id2', 'id4']],\n",
      " 'included': ['metadatas', 'documents', 'distances'],\n",
      " 'metadatas': [[{'chapter': '1', 'verse': 'a'},\n",
      "                {'chapter': '2', 'verse': 'a'},\n",
      "                {'chapter': '1', 'verse': 'a'},\n",
      "                {'chapter': '2', 'verse': 'a'}]],\n",
      " 'uris': None}\n"
     ]
    }
   ],
   "source": [
    "results = collection2.query(\n",
    "    query_texts=[\"This is a query document about hawaii\"], # Chroma will embed this for you\n",
    "    n_results=4 # how many results to return\n",
    ")\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 新增資料\n",
    "因應營運需要，可以在既有的資料庫中持續新增新文檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection2.add(\n",
    "    documents=[\"This is a document about plum\",\n",
    "          \"This is a document about cherry\"],\n",
    "    metadatas=[{\"chapter\": \"3\", \"verse\": \"b\"},\n",
    "          {\"chapter\": \"3\", \"verse\": \"b\"}],\n",
    "    ids=[\"id5\", \"id6\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id1', 'id2', 'id3', 'id4', 'id5', 'id6'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'chapter': '1', 'verse': 'a'},\n",
       "  {'chapter': '1', 'verse': 'a'},\n",
       "  {'chapter': '2', 'verse': 'a'},\n",
       "  {'chapter': '2', 'verse': 'a'},\n",
       "  {'chapter': '3', 'verse': 'b'},\n",
       "  {'chapter': '3', 'verse': 'b'}],\n",
       " 'documents': ['This is a document about pineapple',\n",
       "  'This is a document about oranges',\n",
       "  'This is a document about mango',\n",
       "  'This is a document about apple',\n",
       "  'This is a document about plum',\n",
       "  'This is a document about cherry'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection2.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 檢索特定範圍的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 6, updating n_results = 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['id1', 'id3', 'id2', 'id4']],\n",
       " 'distances': [[1.0404008937271816,\n",
       "   1.1399504747618734,\n",
       "   1.2430800215233073,\n",
       "   1.3259602282234746]],\n",
       " 'metadatas': [[{'chapter': '1', 'verse': 'a'},\n",
       "   {'chapter': '2', 'verse': 'a'},\n",
       "   {'chapter': '1', 'verse': 'a'},\n",
       "   {'chapter': '2', 'verse': 'a'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['This is a document about pineapple',\n",
       "   'This is a document about mango',\n",
       "   'This is a document about oranges',\n",
       "   'This is a document about apple']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 透過 metadata 做過濾\n",
    "collection2.query(\n",
    "    query_texts=[\"This is a query document about hawaii\"],\n",
    "    n_results=10,\n",
    "    where={\"verse\": \"a\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 6, updating n_results = 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['id1', 'id5', 'id4']],\n",
       " 'distances': [[1.0404008937271816, 1.2933018376352365, 1.3259602282234746]],\n",
       " 'metadatas': [[{'chapter': '1', 'verse': 'a'},\n",
       "   {'chapter': '3', 'verse': 'b'},\n",
       "   {'chapter': '2', 'verse': 'a'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['This is a document about pineapple',\n",
       "   'This is a document about plum',\n",
       "   'This is a document about apple']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 檢索文本包含特定文字\n",
    "collection2.query(\n",
    "    query_texts=[\"This is a query document about hawaii\"],\n",
    "    n_results=10,\n",
    "    where_document={\"$contains\":\"p\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 刪除文檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection2.delete(\n",
    "    where={\"verse\": {\"$eq\": \"b\"}}, # 表示 metadata 中 \"author\" 字段值等于 \"jack\" 的文档\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id1', 'id2', 'id3', 'id4'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'chapter': '1', 'verse': 'a'},\n",
       "  {'chapter': '1', 'verse': 'a'},\n",
       "  {'chapter': '2', 'verse': 'a'},\n",
       "  {'chapter': '2', 'verse': 'a'}],\n",
       " 'documents': ['This is a document about pineapple',\n",
       "  'This is a document about oranges',\n",
       "  'This is a document about mango',\n",
       "  'This is a document about apple'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection2.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量化服務\n",
    "- Embeddings may be challenging to scale up, which leads to expensive solutions and high latencies. Currently, many state-of-the-art models produce embeddings with 1024 dimensions, each of which is encoded in float32, i.e., they require 4 bytes per dimension. To perform retrieval over 50 million vectors, you would therefore need around 200GB of memory. This tends to require complex and costly solutions at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tlyu0419\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "corpus = [\"I am driving to the lake.\", \"It is a beautiful day.\"]\n",
    "embeddings = model.encode(corpus)\n",
    "\n",
    "binary_embeddings = model.encode(corpus, precision=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n",
      "3072\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)\n",
    "print(embeddings.nbytes)\n",
    "print(embeddings.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 48)\n",
      "96\n",
      "int8\n"
     ]
    }
   ],
   "source": [
    "print(binary_embeddings.shape)\n",
    "print(binary_embeddings.nbytes)\n",
    "print(binary_embeddings.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text clssification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>A hit at the time but now better categorised a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I love this movie like no other. Another time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>This film and it's sequel Barry Mckenzie holds...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>'The Adventures Of Barry McKenzie' started lif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The story centers around Barry McKenzie who mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1      \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2      If only to avoid making this type of film in t...      0\n",
       "3      This film was probably inspired by Godard's Ma...      0\n",
       "4      Oh, brother...after hearing about this ridicul...      0\n",
       "...                                                  ...    ...\n",
       "24995  A hit at the time but now better categorised a...      1\n",
       "24996  I love this movie like no other. Another time ...      1\n",
       "24997  This film and it's sequel Barry Mckenzie holds...      1\n",
       "24998  'The Adventures Of Barry McKenzie' started lif...      1\n",
       "24999  The story centers around Barry McKenzie who mu...      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('https://huggingface.co/datasets/stanfordnlp/imdb/resolve/main/plain_text/train-00000-of-00001.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 782/782 [18:33<00:00,  1.42s/it]\n",
      "Batches: 100%|██████████| 782/782 [20:01<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "corpus = df['text'].tolist()\n",
    "embeddings = model.encode(corpus, show_progress_bar=True)\n",
    "binary_embeddings = model.encode(corpus, precision=\"binary\", show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.36668587, 0.3979466 , 0.42268515, 0.41765976, 0.37822866]),\n",
       " 'score_time': array([0.01199913, 0.01700163, 0.00935125, 0.0099144 , 0.01199985]),\n",
       " 'test_score': array([0.806 , 0.801 , 0.8006, 0.7982, 0.7984]),\n",
       " 'train_score': array([0.81995, 0.8187 , 0.82145, 0.82275, 0.82205])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(clf, embeddings, df['label'].tolist(), scoring='accuracy', cv=5, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.05052805, 0.04852581, 0.05151486, 0.06106687, 0.05105639]),\n",
       " 'score_time': array([0.00199914, 0.00200224, 0.00199938, 0.00199938, 0.00201774]),\n",
       " 'test_score': array([0.6598, 0.6604, 0.637 , 0.6506, 0.6476]),\n",
       " 'train_score': array([0.65905, 0.6562 , 0.66315, 0.6591 , 0.66025])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(clf, binary_embeddings, df['label'].tolist(), scoring='accuracy', cv=5, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將 Embedding 量化並放入向量資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tlyu0419\\.cache\\huggingface\\hub\\models--infgrad--stella-base-zh-v3-1792d. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at infgrad/stella-base-zh-v3-1792d and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.90356266]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化 Embedding 模型\n",
    "embedding_func = HuggingFaceEmbeddings(\n",
    "    model_name=\"infgrad/stella-base-zh-v3-1792d\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True})\n",
    "\n",
    "# 將字句轉換為向量\n",
    "a = embedding_func.embed_query('突襲式發表！蘋果推 2 款 M3 MacBook Air，強調 AI 、遊戲效能皆強化')\n",
    "b = embedding_func.embed_query('蘋果最新M3版MacBook Air突襲登場！6亮點下放1技術不漲價 M2版還降3000元')\n",
    "\n",
    "# 計算相似度\n",
    "cosine_similarity([a], [b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tlyu0419\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at infgrad/stella-base-zh-v3-1792d and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.72331135]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化 Embedding 模型\n",
    "embedding_func = HuggingFaceEmbeddings(\n",
    "    model_name=\"infgrad/stella-base-zh-v3-1792d\",\n",
    "    encode_kwargs={\"precision\":\"binary\"})\n",
    "\n",
    "# 將字句轉換為向量\n",
    "a = embedding_func.embed_query('突襲式發表！蘋果推 2 款 M3 MacBook Air，強調 AI 、遊戲效能皆強化')\n",
    "b = embedding_func.embed_query('蘋果最新M3版MacBook Air突襲登場！6亮點下放1技術不漲價 M2版還降3000元')\n",
    "\n",
    "# 計算相似度\n",
    "cosine_similarity([a], [b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNextABOUT US廣告合作內容授權新聞最新新聞', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='熱門圖解前端科技產業應用數位生活服務消費企業職場時事焦點AI與大數據5G通訊電動車／交通科技物聯網區塊鏈能源環保醫療生技半導體與電子產業資訊安全智慧製造雲端運算與服務智慧城市遊戲／電競3C生活影音／新媒體教育／人文金融科技新零售服務創新創新創業商業經營行銷與MARTECH職場／工作術程式開發深度專題\\n影音新聞\\n專家觀點社群未來商務創業小聚Web3+活動\\n課程\\n雜誌登入\\n/\\n註冊熱門\\n新聞\\n專題', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='雜誌登入\\n/\\n註冊熱門\\n新聞\\n專題\\n影音\\n活動2023.09.27\\n|\\nAI與大數據LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。＃AI＃openai＃ChatGPTMark LinLLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂2023.09.27\\n|', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='AI與大數據Mark Lin你知道LLM（Large Language', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='Language Model,大型語言模型）是什麼嗎？LLM是一種深度學習模型，透過吸收海量的文本數據學習知識。它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。除了作為聊天機器人，它也被廣泛運用在醫療、開發軟體和服務業，經常出現在日常生活中。想知道它的運作原理、優點與挑戰和其他實際應用？一起來看看這篇文章吧！', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='LLM（大型語言模型）是什麼？', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='大型語言模型（Large Language Model, LLM）是一種深度學習模型，具有超過 1,000 億個參數的自然語言處理（natural language', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='language processing，NLP）系統，經過大量的文本訓練，告訴它已存在的現象，像是新聞、書籍、影音等，使其擁有從海量的知識中識別、匯總、翻譯、預測、生成文字和其他內容的能力。簡單來說，它就是個記憶吐司，能吸收海量的知識，然後回答問題、生成文本、翻譯語言等。例如為產品描述生成文本、回答常見的問題（FAQ）、分析來自社交媒體和產品評論的客戶反饋。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='而 LLM中的「大」是指模型在學習時可以自主更改參數的數量，參數越大代表模型的知識越豐富，能做到的事情也越多 。令人開心的是，它的知識範圍並不僅限於人類語言，還包括生物學語言（例如蛋白質、分子序列）、計算機語言（程式碼）等知識，因此被廣泛地運用在醫療保健、軟體開發、自然科學等領域。\\nLLM 如何運作？用途是什麼？', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='LLM 如何運作？用途是什麼？\\n大型語言模型的工作原理是獲取大量的文本數據，從中學習單詞和句子之間的關係，訓練完畢後可用來分析現有文字的情感與意義或生成新的文本。而且隨著人工智慧的發展，模型能消化的數據集也越來越大，如此大量的文本使用無監督學習輸入人工智慧演算法進行訓練，當它被給予一個數據集而沒有明確的指令要如何處理它時，模型會自己學習單詞以及單詞和語句之間的關係與背後的概念。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='它就像掌握一門語言的知識人，可以猜測句子和段落接下來會發生什麼，甚至想出新的單詞和概念。例如它可以學會根據上下文判斷「感冒」究竟是指身體上的不舒服，還是對某人感到排斥，又或者你和它說「今天心情不好」，它可能會關心你是不是遇到不順心的事情或身體不舒服等等。此外，大型語言模型也可以針對特定用例進行定製，通過微調或提示調整等技術，向模型提供少量數據以針對特定應用程式進行訓練。LLM是一種深度學習模型，', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='程式進行訓練。LLM是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。圖／', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='ShutterstockLLM 是怎麼訓練的？', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='大多數LLM都是在一個大型的、未經過標記的數據集上進行預先訓練（Pre-Training），之後會再根據不同需求判斷是否需要進行微調（Fine-Tuning），這時會加入少量的、以標記的數據集。訓練過程包括：處理文字數據，將其轉換為可用於模型中的數位表示形式\\n隨機分配模型的參數\\n將文本數據的數位表示形式傳送至模型中\\n使用損失函數來測量模型的輸出與句子中實際的下一個單詞之間的差異', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='優化模型的參數以最大程度地減少損失', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='重複該過程，直到模型的輸出達到可接受的精度級別大型語言模型可以應用於不同種類的語言或場景，這不僅擴大了人工智慧的覆蓋範圍，也有望實現新一波的研究、創造力和生產力，因為它們可以為棘手的問題生成複雜的解決方案。例如，讓模型從分子和蛋白質結構資料庫中學習，然後利用這些知識提供可行的化合物，幫助科學家開發突破性的疫苗或治療方法；或是，信用卡公司使用LLM 進行異常檢測和欺詐分析，保護消費者。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='LLM 為何颳起風潮？', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='大型語言模型的初衷其實源自於2010年的機器學習，因為機器本身無法思考、也無法吸收世界上所有的知識，因此科學家們退而求其次，先教會機器識字後，告訴它大量的現象，讓它自行判斷。幸運的事，機器找出了自己的規律、然後學習，這讓人工智慧有了大幅度的進步。後來從機器學習中發展出「深度學習」，讓電腦更好地從海量的資料中發展出可應用的模型，2014年的AlphaGo', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='就是一個經典例子。之後也陸續出現其他的深度學習模型，而其中擁有大量資料與參數的語言模型就是LLM。AlphaGo Lee（左）與李世乭（右）對弈轉播畫面。圖／', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='gogameguru.com隨著大型語言模型的發展歷程，2019年Google推出的BERT語言模型與OpenAI推出的GPT語言模型都被證實具備相當的知識與能力，2020年OpenAI發布的GPT-3可以透過簡短的書面提示生成文字和程式碼，2021年NVIDIA和微軟開發了MT-NLP，可以簡化摘要和內容生成等任務，2022年HuggingFace推出了能夠以46種自然語言和十幾種程式設計語言', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='能夠以46種自然語言和十幾種程式設計語言生成文字的開放大型語言模型BLOOM，2023年風靡全球的ChatGPT，可以看出LLM的複雜度與規模都逐漸增加。過去幾年LLM皆以每年10倍的速度快速成長，它已成為人工智慧發展不可或缺的關鍵。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='大型語言模型的優點與挑戰\\n大型語言模型除了能了解單詞和語句之間的複雜關係，從而生出新的文字，也有助於創建重新設計的搜尋引擎、輔導聊天機器人、歌曲、詩歌、故事和行銷材料的創作工具。除此之外，它還具備許多優點，介紹如下：', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='1. 增加可用性、個人化和顧客滿意度： 許多客戶希望服務不受時間限制，可以全天候使用，LLM 的聊天機器人和虛擬助手正好可以滿足這項需求。通過自動化內容創建，語言模型可以通過處理大量數據來瞭解客戶行為和偏好，從而推動個人化。客戶滿意度將隨著可用性和個人化服務而增加。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='2. 節省時間： 行銷、銷售、人力資源和客戶服務中的許多流程都可以使用LLM 來執行，使員工將精力花費在更重要的事情上。例如，欺詐檢測、數據輸入、客戶服務和文檔創建等。此外，語言模型分析大量數據的能力可以幫助企業從複雜的數據集中快速提取重要資訊，提高營運效率。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='3. 提高任務準確性： LLM 能夠處理大量數據，進而提高預測和分類的準確性。例如，在情緒分析中，大型語言模型可以分析數千條客戶評論，以瞭解其背後的情緒，從而提高確定客戶評論是正面、負面還是中立的準確性。這項能力在業務應用程式中特別重要，因為小錯誤可能會產生重大影響。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='然而除了上述的優點，大型語言模型其實也存在不少挑戰。建構基礎模型通常需要花費數月的培訓時間和數百萬美元，後續地擴展與維護同樣需要大量的資金。而且LLM除了大量的計算能力外，對深度學習、轉換器模型和分散式軟體與硬體也需要有深刻理解，如何獲得足夠的訓練數據也相當具有挑戰。這個領域具備結實的科技保護傘，進入難度高。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='在實際運用上，因為模型的知識範圍僅限於所訓練的文字數據，因此它們對世界的理解有限。 而且當訓練數據集沒有被檢查和標記時，語言模型已被證明會做出種族主義或性別歧視的評論。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='在某些情況下，還會提供虛假資訊。例如，微軟曾推出一款Twitter聊天機器人Tay，是一款使用公共數據的人工智慧，和它聊天的次數越多它會變得越聰明。然而，Tay在Twitter上發布不到24小時就被各種厭惡女性、種族主義的言論汙染，將女權主義稱為邪教和癌症，並將性別平等與女權主義畫上等號。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='LLM 的應用\\n大型語言模型適用於各種產業，正以搜尋引擎、自然語言處理、醫療保健、機器人和代碼生成等領域開創新的可能性。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='ChatGPT AI聊天機器人，背後的運作原理就是LLM的一個應用，可以用於無數的自然語言處理，它在幾秒內就能生成一篇精美文章的能力令人驚嘆。Meta於2023年2月25日推出的LLaMA', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='也是LLM的應用之一。Meta形容它是一個更小、性能更好的模型，能協助研究人員工作。聯發科也在2月公開釋出以開源語言模型BLOOM開發的繁體中文大型語言模型，可應用於問答系統、文字編修、廣告文案生成、華語教學、客服系統等。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='除此之外，在我們的生活中其實就存在許多LLM的應用，像是手機的AI客服等都是透過聊天機器人和人工智慧來提升客戶的產品體驗；行銷人員透過訓練模型，讓它幫忙根據產品描述將產品分類；開發人員也能利用它編寫軟體。宛如超級大腦的大型語言模型，每年持續升級，具備越來越多功能，帶動人工智慧也不斷進步，期待它未來能解決更多複雜的問題，並為生活帶來更多的便利。\\n本文授權轉載自：馬克解讀金融科技關鍵字：\\n＃AI', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='＃AI\\n＃openai\\n＃ChatGPT本網站內容未經允許，不得轉載。往下滑看下一篇文章即時熱門文章1\\n上班時間去旅行，休假不跟主管說！職場新趨勢「安靜度假」是什麼？2\\n補貼來了！無薪假最高月領9,200元、就業獎勵最高13,000元，如何申請？9新制一次看3\\n宜鼎強攻「邊緣AI」！開案量看漲3成，為何選址宜蘭？邊緣運算是什麼？4', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='3G網路關閉倒數！3G手機不能用了怎麼辦？怎麼換VoLTE？問答一次看5\\n酷澎「負毛利戰法」殺進台灣！本土電商momo、PChome怎接招？詹宏志為何說「無解」？6\\nNike崩跌！單日蒸發284億美元創紀錄，發生什麼事？Nike球鞋不潮了？一文解密Nike財報即時熱門文章1\\n上班時間去旅行，休假不跟主管說！職場新趨勢「安靜度假」是什麼？2', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='補貼來了！無薪假最高月領9,200元、就業獎勵最高13,000元，如何申請？9新制一次看3\\n宜鼎強攻「邊緣AI」！開案量看漲3成，為何選址宜蘭？邊緣運算是什麼？4\\n3G網路關閉倒數！3G手機不能用了怎麼辦？怎麼換VoLTE？問答一次看5\\n酷澎「負毛利戰法」殺進台灣！本土電商momo、PChome怎接招？詹宏志為何說「無解」？6', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='Nike崩跌！單日蒸發284億美元創紀錄，發生什麼事？Nike球鞋不潮了？一文解密Nike財報2024.06.24\\n|打破數據孤島，實現數據驅動！直通國際ESi「顧客資料平台CDP」助品牌實現行銷自動化', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='數據孤島是許多企業面臨的棘手挑戰。對此，直通國際ESi的CDP平台，透過一站式數據整合，逐步提升行銷精準度與效率，推動品牌朝向個人化、自動化行銷邁進。sponsored by直通國際打破數據孤島，實現數據驅動！直通國際ESi「顧客資料平台CDP」助品牌實現行銷自動化2024.06.24', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='|sponsored by直通國際「在數據驅動行銷的過程中，企業最常遇到的挑戰之一是數據孤島（Data', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='Silos）問題。新的行銷系統上線後，各系統間的數據斷點常成為企業運作的瓶頸。」直通國際ESi共同創辦人吳彥霆指出，隨著數位轉型浪潮席捲全球，企業對數據價值的重視與日俱增，但在數據整合與應用的過程中，仍面臨諸多挑戰。而成立於2006年的直通國際ESi，一直以來專注於數據驅動的數位行銷整合方案，主張唯有透過全面掌握會員樣貌，才能實現行銷效能最大化，推動企業營收成長。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='打破數據孤島，專為行銷而生的顧客資料平台CDP\\n「許多中小企業常會點狀購買解決方案，這樣雖能解決某些特定問題，但無法徹底解決數據斷點的狀況——而這正是顧客資料平台（Customer Data Platform，CDP）能解決的核心問題。」吳彥霆表示，CDP的優勢在於能一次性整合所有相關數據，避免數據重複與遺漏，提升企業數據應用效能。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='看似與CRM（Customer Relationship Management，客戶關係管理）系統概念很像，其實不然。吳彥霆指出，直通國際ESi擁有長年豐富的CRM經驗，觀察到許多企業雖掌握大量客戶數據，但資料探勘流程繁瑣，更難以為行銷人員使用。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='而CDP的導入，吳彥霆比喻，就像是專為行銷人員打造的CRM，能為行銷人員建立獨立的資料庫，使數據探索與應用更加迅速與精準，大大提升行銷效率。無論是大型或中小型企業，都能客製化屬於自己的CDP平台，為行銷團隊實現跨通路的數據整合與收斂應用，加速內部流程、提升外部行銷效益。圖／', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='數位時代與直通國際ESi合作多年的國泰世華銀行協理陳麗薰說明，金融業仰賴多種通路蒐集使用者數據，包括銀行App、ATM、官網和客服中心等，然而這些數據各自獨立、難以整合，更導致行銷人員在鎖定目標客群時只能土法煉鋼，花費大量時間進行數據探勘、反覆製作受眾名單。如今，運用直通國際ESi的CDP解決方案，不僅將客戶的跨通路數據整併，建立360度顧客檔案，為個人化金融體驗奠定基礎，行銷人員更可以在後台視', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='金融體驗奠定基礎，行銷人員更可以在後台視覺化地檢視數據，迅速拖拉點選、自行組裝受眾名單，大幅加快作業流程。不只金融業，在電商產業中，CDP帶動業績成長的效果更加顯著。圖／', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='數位時代吳彥霆以母嬰品牌客戶為例，該品牌在導入CDP後，一年內會員數量增長了34%，營收增長了64%，客單價也大幅提升。「透過CDP的數據整合與應用，將客戶由淺入深分門別類，不只幫助品牌優化了行銷漏斗，也形同補破網，將過去遺失的淺層接觸客戶也一網打盡！」', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='無斷點的MarTech，CDP為品牌實踐終極的數據驅動\\n吳彥霆強調，「行銷自動化，就是CDP的核心目標。」CDP能為品牌做好數據驅動的基礎建設，在MarTech中扮演著關鍵的戰略角色，不只能透過數據整合，為行銷策略端提供全局視角，同時也能節省行銷人員庶務，自動化處理「消費者回購提醒」等例行公事，釋放行銷人員動能，專注在更大的客戶洞察與價值展現上。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='「下一步，生成式人工智慧（GenAI）會是趨勢。如何實現大規模個人化行銷，針對不同階段的客戶提供個人化內容，這都需要與CDP進行緊密串接。」吳彥霆指出，隨著技術的不斷發展，GenAI的創新應用指日可待，也將進一步提升CDP的價值，為品牌實現數據驅動行銷提供更多可能。', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='有關更多ESi直通國際相關資訊，請查詢網站：https://www.ESi-tech.net/本網站內容未經允許，不得轉載。即時熱門文章1\\n上班時間去旅行，休假不跟主管說！職場新趨勢「安靜度假」是什麼？2\\n補貼來了！無薪假最高月領9,200元、就業獎勵最高13,000元，如何申請？9新制一次看3\\n宜鼎強攻「邊緣AI」！開案量看漲3成，為何選址宜蘭？邊緣運算是什麼？4', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='3G網路關閉倒數！3G手機不能用了怎麼辦？怎麼換VoLTE？問答一次看5\\n酷澎「負毛利戰法」殺進台灣！本土電商momo、PChome怎接招？詹宏志為何說「無解」？6\\nNike崩跌！單日蒸發284億美元創紀錄，發生什麼事？Nike球鞋不潮了？一文解密Nike財報即時熱門文章1\\n上班時間去旅行，休假不跟主管說！職場新趨勢「安靜度假」是什麼？2', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='補貼來了！無薪假最高月領9,200元、就業獎勵最高13,000元，如何申請？9新制一次看3\\n宜鼎強攻「邊緣AI」！開案量看漲3成，為何選址宜蘭？邊緣運算是什麼？4\\n3G網路關閉倒數！3G手機不能用了怎麼辦？怎麼換VoLTE？問答一次看5\\n酷澎「負毛利戰法」殺進台灣！本土電商momo、PChome怎接招？詹宏志為何說「無解」？6', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='Nike崩跌！單日蒸發284億美元創紀錄，發生什麼事？Nike球鞋不潮了？一文解密Nike財報追蹤我們影音新聞會員登入新聞最新新聞\\n深度專題\\n熱門圖解', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='深度專題\\n熱門圖解\\n專家觀點主題分類前端科技5G通訊AI與大數據電動車／交通科技物聯網區塊鏈能源環保產業應用半導體與電子產業醫療生技資訊安全智慧城市智慧製造雲端運算與服務企業職場商業經營創新創業行銷與MARTECH職場／工作術程式開發產業動態服務消費新零售金融科技服務創新數位生活3C生活遊戲／電競影音／新媒體教育／人文數位行銷學院課程一覽\\n線上學習\\n企業內訓\\n團票預購品牌活動社群活動\\n未來商務展', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='團票預購品牌活動社群活動\\n未來商務展\\nMeet Taipei品牌社群未來商務\\nMeet創業小聚\\nWeb3+雜誌最新出刊\\n訂閱優惠關於我們\\n內容轉載規範\\n服務條款與隱私權政策\\n廣告刊登\\n徵才\\n聯絡我們客服信箱：service@bnext.com.tw\\n客服專線：886-2-87716326\\n服務時間：週一 ～ 週五：09:30~12:00；13:30~17:00', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='106 台北市大安區光復南路102號9樓影音 登入 新聞最新新聞\\n深度專題\\n熱門圖解\\n專家觀點課程數位行銷學院\\n線上學習\\n企業內訓\\n團票預購品牌活動社群活動\\n未來商務展\\nMeet Taipei品牌社群未來商務\\nMeet創業小聚\\nWeb3+雜誌最新出刊', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='Web3+雜誌最新出刊\\n訂閱優惠追蹤我們主題分類前端科技5G通訊AI與大數據電動車／交通科技物聯網區塊鏈能源環保產業應用半導體與電子產業醫療生技資訊安全智慧城市智慧製造雲端運算與服務企業職場商業經營創新創業行銷與MARTECH職場／工作術程式開發產業動態服務消費新零售金融科技服務創新數位生活3C生活遊戲／電競影音／新媒體教育／人文關於我們\\n內容轉載規範\\n服務條款與隱私權政策\\n廣告刊登\\n徵才', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='服務條款與隱私權政策\\n廣告刊登\\n徵才\\n聯絡我們客服信箱：service@bnext.com.tw\\n客服專線：886-2-87716326\\n服務時間：週一 ～ 週五：09:30~12:00；13:30~17:00\\n106 台北市大安區光復南路102號9樓登入數位時代會員\\n開啟專屬自己的主題內容，\\n每日推播重點文章閱讀會員專屬文章\\n請先登入數位時代會員看更多獨享內容', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='請先登入數位時代會員看更多獨享內容\\n請先登入數位時代會員開啟收藏文章功能，\\n請先登入數位時代會員開啟訂閱文章分類功能，\\n請先登入數位時代會員登入看看我還不是會員， 註冊去！熱門分類職場/工作術\\n時事焦點\\n半導體與電子產業\\n5G通訊\\n新零售今日熱門1\\n上班時間去旅行，休假不跟主管說！職場新趨勢「安靜度假」是什麼？2', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='補貼來了！無薪假最高月領9,200元、就業獎勵最高13,000元，如何申請？9新制一次看3\\n宜鼎強攻「邊緣AI」！開案量看漲3成，為何選址宜蘭？邊緣運算是什麼？追蹤我們新商業的領航者|AboutUs |廣告合作 |徵才 |隱私權政策|客服信箱：service@bnext.com.tw客服專線：886-2-87716326', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='服務時間：週一 ～ 週五：09:30~12:00；13:30~17:00媒體數位時代經理人Shopping Design創業小聚未來商務Web3+學習新商業學校線上課程課程團票方案企業內訓計畫產品管理知識庫經理人新書快讀EventGO活動平台展會Meet Taipei 創新創業嘉年華Meet Greater SouthFuture Commerce 未來商務展|AboutUs |廣告合作 |徵才', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='|廣告合作 |徵才 |隱私權政策|客服信箱：service@bnext.com.tw客服專線：886-2-87716326', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'}),\n",
      " Document(page_content='服務時間：週一 ～ 週五：09:30~12:00；13:30~17:00© 2024 Business Next Media Corp. All Rights Reserved. 本網站內容未經允許，不得轉載。106台北市大安區光復南路102號9樓', metadata={'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext', 'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW'})]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm\"\n",
    "\n",
    "loader = WebBaseLoader(url)\n",
    "news_docs = loader.load()\n",
    "news_docs[0].page_content = re.sub('\\n\\s+', '',news_docs[0].page_content)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20)\n",
    "texts_chunks = text_splitter.split_documents(news_docs)\n",
    "pprint(texts_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Document(page_content='LLM（大型語言模型）是什麼？', metadata={'description': 'LLM（大型語言模型）是一種深度學習模型，它能從大量的文章、影音、書籍中學習單詞和句子之間的關係，然後回答問題、翻譯、生成文本。', 'language': 'zh-Hant-TW', 'source': 'https://www.bnext.com.tw/article/76864/what-is-the-meaning-of-llm', 'title': 'LLM是什麼？跟AI的關聯為何？大型語言模型要面對什麼挑戰？一文看懂|數位時代 BusinessNext'}),\n",
       " 800762.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load it into Chroma\n",
    "db = Chroma.from_documents(texts_chunks, embedding_func)\n",
    "\n",
    "# query it\n",
    "query = \"什麼是 LLM 模型？\"\n",
    "docs = db.similarity_search_with_score(query)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "- 量化雖然能加速，但也會掉精準度，值不值得就看專案的需求\n",
    "- 也因此後面有發展出許多其他量化的技術，嘗試在加速的同事不要掉太多效度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
